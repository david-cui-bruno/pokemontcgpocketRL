---
description: 
globs: 
alwaysApply: false
---
---
description: Core rules for the PokÃ©mon-TCG-Pocket RL engine
globs:
  - "**/*.py"
alwaysApply: true
---

# ğŸ“¦ Project overview
You are editing a **research-grade reinforcement-learning engine** that learns to play _PokÃ©mon TCG Pocket_ like a chess engine.

Key architectural layers (all in `src/`):

1. `card_db/`   â€“ parses card JSON and exposes immutable dataclasses  
2. `rules/`     â€“ deterministic game simulator (~100 ns/step target)  
3. `env/`       â€“ Gym-compatible wrapper returning masks & rewards  
4. `net/`       â€“ PyTorch policy-value nets; no business logic here  
5. `train/`     â€“ Lightning loops, distributed via Ray  
6. `serve/`     â€“ FastAPI â€œbest-moveâ€ service + ONNX runtime  

# âœï¸ Coding style & tooling
* **Python 3.11**, PEP 8 + Ruff + Black (line-length 100)  
* Mandatory **type hints** everywhere; enable `pyright.strict`  
* Pure functions or stateless classes inside `rules/`; RNG only in `env/`  
* Write **NumPy-style docstrings** with examples  
* Keep files â‰¤ 400 LOC; split logically if you exceed this  
# âœ… Testing contract
* Each new rule or card effect must ship with a pytest in `tests/rules/`  
* Achieve â‰¥ 90 % line coverage for `rules/`  
* Use Hypothesis for property tests (e.g., energy-attachment invariants)  
* CI fails if coverage, Ruff, Black or MyPy checks fail  

# ğŸš¦ Performance guard-rails
* `rules/*.py` **must not** import PyTorch or Ray  
* Simulator step budget: **â‰¤ 150 Âµs** on an M2 CPU core  
  â€“ Profile with `python -m rules.bench` before committing  
* Avoid recursion deeper than evolution-stack length (â‰¤ 3); prefer loops here  

# ğŸ›‘ Prohibited patterns
* No global mutable singletons (use dependency injection)  
* No hard-coded file paths; use `importlib.resources` or `Path(__file__).parent`  
* No bare `assert` in library code â€“ raise explicit exceptions  
* Never seed RNGs in library modules; leave that to the caller  

# ğŸ”„ Editor integrations
* `pyproject.toml` defines deps (PyTorch â‰¥ 2.3, Gymnasium â‰¥ 1.0, Ray â‰¥ 2.9)  
* `Makefile` has convenience targets: `make format`, `make test`, `make bench`  
* Run `make prepush` locally; the pre-commit hook mirrors CI  

# ğŸ—‚ï¸ Folder conventions
src/
card_db/          # immutable data
rules/            # pure game logic
env/              # RL wrapper
net/              # models
train/            # training scripts
serve/            # inference API
tests/
rules/
env/
integration/

# ğŸ‘©â€ğŸ’» When writing code
* Prefer **dataclasses** (`@dataclass(frozen=True)`) for state snapshots  
* Surface **action masks** as `torch.bool` tensors shaped `[A]`  
* Log with the std-lib `logging` module; default level INFO

# Helpful prompts for Cursor Agent
* â€œGenerate unit tests for the new card effect in `rules/effects/damage_swap.py`.â€  
* â€œRefactor `train/ppo_loop.py` to batch env steps across Ray actors.â€  
